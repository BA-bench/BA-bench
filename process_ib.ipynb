{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Template\n",
    "{\n",
    "    'id': str,  # Unique identifier for each sample\n",
    "    'question': str,  # A business-related question related to the data\n",
    "    'data_file': str,  # The data file the question relates to\n",
    "    'doc_file': str,  # The document file the question relates to\n",
    "    'answer': str,  # The answer to the question\n",
    "    'data_domain': str,  # The domain the data belongs to (e.g., finance, education)\n",
    "    'analysis_type': str,  # The type of question, optional: [\"Structure problems\", \"Unstructured problems\", \"Chart problems\"]\n",
    "    'origin_from': list[str],  # Source of the question, e.g., ['benchmark name', 'question id']\n",
    "    'additional_information': list[dict[str, str]],  # Additional information such as code, statistical results, intermediate steps (e.g., StatQA's analysis methods) etc.\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前目录: ./insight-bench/data/notebooks\n",
      "当前目录: ./insight-bench/data/notebooks/csvs\n"
     ]
    }
   ],
   "source": [
    "import srsly\n",
    "import os\n",
    "\n",
    "folder_path = \"./insight-bench/data/notebooks\"\n",
    "data = []\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    print(f\"当前目录: {root}\")\n",
    "    # for dir_name in dirs:\n",
    "    #     print(f\"文件夹: {os.path.join(root, dir_name)}\")\n",
    "    for file_name in files:\n",
    "        if file_name.endswith(\".json\"):\n",
    "            json_data = srsly.read_json(os.path.join(root, file_name))\n",
    "            data.append(json_data)\n",
    "        # print(f\"文件: {os.path.join(root, file_name)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/notebooks/csvs/flag-13.csv\n",
      "data/notebooks/csvs/flag-53.csv\n",
      "data/notebooks/csvs/flag-7.csv\n",
      "data/notebooks/csvs/flag-62.csv\n",
      "data/notebooks/csvs/flag-15.csv\n",
      "data/notebooks/csvs/flag-55.csv\n",
      "data/notebooks/csvs/flag-14.csv\n",
      "data/notebooks/csvs/flag-6.csv\n",
      "data/notebooks/csvs/flag-56.csv\n",
      "data/notebooks/csvs/flag-9.csv\n",
      "data/notebooks/csvs/flag-8.csv\n"
     ]
    }
   ],
   "source": [
    "IB_insight_res = []\n",
    "pref = 'InsB'\n",
    "i = 0\n",
    "for idx,insight_item in enumerate(data):\n",
    "    insight_ls = insight_item['insight_list']\n",
    "    csv_name = insight_item['dataset_csv_path']\n",
    "    data_domian = insight_item['metadata']['category']\n",
    "    data_desc = insight_item['metadata']['dataset_description']\n",
    "    for item  in insight_ls:\n",
    "        add_info = []\n",
    "        for k,v in item.items():\n",
    "            if k not in ['question','insight']:\n",
    "                add_info.append({k:v})\n",
    "        if 'question' not in item.keys():\n",
    "            # print(item.keys())\n",
    "            print(csv_name)\n",
    "            continue\n",
    "        tem_ques = {\n",
    "            'id': pref+'_'+str(i),\n",
    "            'question': item['question'],\n",
    "            'data_file': csv_name,  \n",
    "            'doc_file': 'None',  \n",
    "            'answer': item['insight'], \n",
    "            'data_domain': data_domian,  # The domain the data belongs to (e.g., finance, education)\n",
    "            'analysis_type': \"Unstructured problems\",  # The type of question, optional: [\"Structure problems\", \"Unstructured problems\", \"Chart problems\"]\n",
    "            'origin_from': ['Insight_bench',csv_name.split('/')[-1].replace('.csv','')],  # Source of the question, e.g., ['benchmark name', 'question id']\n",
    "            'additional_information': add_info,  # Additional information such as code, statistical results, intermediate steps (e.g., StatQA's analysis methods) etc.\n",
    "        }\n",
    "        IB_insight_res.append(tem_ques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IB_chart_res = []\n",
    "pref = 'InsB_Chart'\n",
    "i = 0\n",
    "for idx,insight_item in enumerate(data):\n",
    "    insight_ls = insight_item['insight_list']\n",
    "    csv_name = insight_item['dataset_csv_path']\n",
    "    data_domian = insight_item['metadata']['category']\n",
    "    data_desc = insight_item['metadata']['dataset_description']\n",
    "    for item  in insight_ls:\n",
    "        add_info = []\n",
    "        for k,v in item.items():\n",
    "            if k not in ['question','insight','plot']:\n",
    "                add_info.append({k:v})\n",
    "        if 'question' not in item.keys():\n",
    "            # print(item.keys())\n",
    "            # print(csv_name)\n",
    "            continue\n",
    "        if 'plot' not in item.keys():\n",
    "            # print(item.keys())\n",
    "            # print(csv_name)\n",
    "            continue\n",
    "        tem_ques = {\n",
    "            'id': pref+'_'+str(i),\n",
    "            'question': item['question'],\n",
    "            'data_file': csv_name,  \n",
    "            'doc_file': 'None',  \n",
    "            'answer': item['plot'], \n",
    "            'data_domain': data_domian,  # The domain the data belongs to (e.g., finance, education)\n",
    "            'analysis_type': \"Chart problems\",  # The type of question, optional: [\"Structure problems\", \"Unstructured problems\", \"Chart problems\"]\n",
    "            'origin_from': ['Insight_bench',csv_name.split('/')[-1].replace('.csv','')],  # Source of the question, e.g., ['benchmark name', 'question id']\n",
    "            'additional_information': add_info,  # Additional information such as code, statistical results, intermediate steps (e.g., StatQA's analysis methods) etc.\n",
    "        }\n",
    "        IB_chart_res.append(tem_ques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417 335\n"
     ]
    }
   ],
   "source": [
    "print(len(IB_insight_res),len(IB_chart_res))\n",
    "final_res = IB_insight_res+IB_chart_res\n",
    "out_path = './BA_data_v0(InsightBench).json'\n",
    "srsly.write_json(out_path,final_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
